{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialmente é realizando o load das bibliotecas necessárias para o processo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 09:20:47.605614: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-24 09:20:47.605648: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-08-24 09:20:48.852204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-24 09:20:48.852234: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-24 09:20:48.852250: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (calixto-VirtualBox): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# core\n",
    "from json import load as jsload\n",
    "from warnings import catch_warnings, filterwarnings\n",
    "from random import shuffle\n",
    "from time import strftime, mktime\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from sqlite3 import connect\n",
    "# Captação dos dados\n",
    "from tweepy import OAuthHandler, API\n",
    "# NLP\n",
    "from spacy import load\n",
    "# Auxiliar\n",
    "from emoji import is_emoji\n",
    "from labels import mapping\n",
    "# Deep Learning\n",
    "from tez import Model\n",
    "from torch import sigmoid, no_grad, LongTensor, sort as torch_sort\n",
    "from torch.nn import Dropout, Linear, BCEWithLogitsLoss\n",
    "from transformers import SqueezeBertModel, SqueezeBertTokenizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a conexão com o banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_tweets = \"CREATE TABLE IF NOT EXISTS tweets (tweet_id TEXT PRIMARY KEY, user_id TEXT NOT NULL, sentments TEXT, sent_score INTEGER NOT NULL, favorited INTEGER, retweets INTEGER, created_at INTEGER NOT NULL, text TEXT NOT NULL, hashtags TEXT, mentions TEXT, urls TEXT, type TEXT, is_retweet INTEGER, crypto TEXT, FOREIGN KEY (sentments) REFERENCES sentment (sentment_id));\"\n",
    "create_table_users = \"CREATE TABLE IF NOT EXISTS users (user_id TEXT PRIMARY KEY, screen_name TEXT, followers INTEGER);\"\n",
    "create_table_sentment = \"CREATE TABLE IF NOT EXISTS sentment (sentment_id INTEGER PRIMARY KEY, sentment_char TEXT);\"\n",
    "create_table_indexes = \"CREATE TABLE IF NOT EXISTS indexes (index_id INTEGER PRIMARY KEY, forecast REAL NOT NULL, cryptocurrency TEXT NOT NULL, timestamp INTEGER NOT NULL);\"\n",
    "insert_table_tweets = \"INSERT INTO tweets(tweet_id, user_id, sentments, sent_score, favorited, retweets, created_at, text, hashtags, mentions, urls, type, is_retweet, crypto) VALUES ('{}', '{}', '{}', {}, {}, {}, {}, '{}', '{}', '{}', '{}', '{}', '{}', '{}')\"\n",
    "insert_table_users = \"INSERT INTO users(user_id, screen_name, followers) VALUES ('{}', '{}', {})\"\n",
    "insert_table_sentment = \"INSERT INTO sentment(sentment_id, sentment_char) VALUES ({}, '{}')\"\n",
    "insert_table_indexes = \"INSERT INTO indexes(index_id, forecast, cryptocurrency, timestamp) VALUES ({}, {}, '{}', {})\"\n",
    "select_table_users = \"SELECT * FROM users WHERE user_id = {}\"\n",
    "select_table_tweets = \"SELECT * FROM tweets WHERE tweet_id = {}\"\n",
    "update_table_users = \"UPDATE users SET followers = {} WHERE user_id = {}\"\n",
    "\n",
    "try:\n",
    "    conn = connect(\".\\cryptobot10.db\")\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(create_table_tweets)\n",
    "    cursor.execute(create_table_users)\n",
    "    cursor.execute(create_table_sentment)\n",
    "    cursor.execute(create_table_indexes)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando o load modelo pré treinado spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coloquei as chaves de acesso a minha conta no Twitter em um arquivo separado :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"key.json\") as file:\n",
    "    keys = jsload(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(\n",
    "    consumer_key = keys[\"API key\"],\n",
    "    consumer_secret = keys[\"API secret key\"]\n",
    ")\n",
    "\n",
    "auth.set_access_token(\n",
    "    key = keys[\"Access token\"],\n",
    "    secret = keys[\"Access token secret\"]\n",
    ")\n",
    "api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o modelo treinado para identificação das emoções em textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    def __init__(self):\n",
    "        self.val_strategy = \"batch\"\n",
    "\n",
    "class EmotionClassifier(Model):\n",
    "    def __init__(self, num_train_steps, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = SqueezeBertModel.from_pretrained(\"squeezebert/squeezebert-uncased\")\n",
    "        self.bert_drop = Dropout(0.3)\n",
    "        self.out = Linear(768, num_classes)\n",
    "    \n",
    "    def forward(self, ids, mask, targets= None):\n",
    "        o_2 = self.bert(ids, attention_mask=mask)[\"pooler_output\"]\n",
    "        b_o = self.bert_drop(o_2)\n",
    "        output = self.out(b_o)\n",
    "        loss = self.loss(output, targets)\n",
    "        acc = self.monitor_metrics(output, targets)\n",
    "        return output, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at squeezebert/squeezebert-uncased were not used when initializing SqueezeBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing SqueezeBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SqueezeBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = EmotionClassifier(int(43410 / 32 * 10), len(mapping))\n",
    "model.load(\"export/model.bin\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a função de identificação dos sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentence(text, topn=5):\n",
    "    final_classification = {}\n",
    "    tokenizer = SqueezeBertTokenizer.from_pretrained(\"squeezebert/squeezebert-uncased\", do_lower_case=True)\n",
    "    max_len = 35\n",
    "    with no_grad():\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        ids = LongTensor(ids).cpu().unsqueeze(0)\n",
    "        \n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        attention_mask = LongTensor(attention_mask).cpu().unsqueeze(0)\n",
    "        \n",
    "        output = model.forward(ids, attention_mask)[0]\n",
    "        output = sigmoid(output)\n",
    "        \n",
    "        probas, indices = torch_sort(output)\n",
    "        \n",
    "    probas = probas.cpu().numpy()[0][::-1]\n",
    "    indices = indices.cpu().numpy()[0][::-1]\n",
    "    \n",
    "    for i, p in zip(indices[:topn], probas[:topn]):\n",
    "        final_classification[mapping[i]] = p\n",
    "        \n",
    "    return final_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando função para estruturação das predições e tratamento dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tabela de pesos para cada sentimento\n",
    "sent_pesos = {\n",
    "    \"admiration\":8,\n",
    "    \"amusement\":4,\n",
    "    \"anger\":-7,\n",
    "    \"annoyance\":-9,\n",
    "    \"approval\":7,\n",
    "    \"caring\":-8,\n",
    "    \"confusion\":-5,\n",
    "    \"curiosity\":5,\n",
    "    \"desire\":9,\n",
    "    \"disappointment\":-10,\n",
    "    \"disapproval\":-9,\n",
    "    \"disgust\":-5,\n",
    "    \"embarrassment\":-6,\n",
    "    \"excitement\":10,\n",
    "    \"fear\":-8,\n",
    "    \"gratitude\":6,\n",
    "    \"grief\":-2,\n",
    "    \"joy\":1,\n",
    "    \"love\":2,\n",
    "    \"nervousness\":-4,\n",
    "    \"optimism\":10,\n",
    "    \"pride\":8,\n",
    "    \"realization\":3,\n",
    "    \"relief\":4,\n",
    "    \"remorse\":-10,\n",
    "    \"sadness\":-3,\n",
    "    \"surprise\":1,\n",
    "    \"neutral\":0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caracters_to_remove(w):\n",
    "    return any([\n",
    "                  w.is_bracket\n",
    "                , w.is_punct\n",
    "                , w.is_quote\n",
    "                , w.is_stop\n",
    "                , w.is_space\n",
    "                , w.text in [\"\\n\"]\n",
    "                , not w.i and w.text == \"RT\"\n",
    "                , is_emoji(w.text)\n",
    "                ])\n",
    "\n",
    "def format_date(d):\n",
    "    return int(mktime(datetime.strptime(d, \"%a %b %d %H:%M:%S +0000 %Y\").timetuple()))\n",
    "\n",
    "def buildStructure(raw_tweet):\n",
    "    tweet = dict(raw_tweet._json)\n",
    "    clean_text = \" \".join([w.text for w in nlp(tweet[\"full_text\"]) if not caracters_to_remove(w)]).replace(\"'\", \"\")\n",
    "    \n",
    "    sentments = score_sentence(clean_text)\n",
    "    \n",
    "    structure = {\n",
    "        \"user_id\" : tweet[\"user\"][\"id_str\"],\n",
    "        \"screen_name\" : tweet[\"user\"][\"screen_name\"],\n",
    "        \"followers\" : tweet[\"user\"][\"followers_count\"],\n",
    "        \"retweet_count\" : tweet[\"retweet_count\"],\n",
    "        \"favorited\" : tweet[\"favorited\"],\n",
    "        \"created_at\": format_date(tweet[\"created_at\"]),\n",
    "        \"id\": tweet[\"id_str\"],\n",
    "        \"text\": clean_text,\n",
    "        \"hashtags\": [h[\"text\"] for h in tweet[\"entities\"][\"hashtags\"]],\n",
    "        \"user_mentions\": [m[\"screen_name\"] for m in tweet[\"entities\"][\"user_mentions\"]],\n",
    "        \"urls\": tweet[\"entities\"][\"urls\"],\n",
    "        \"type\": tweet[\"metadata\"][\"result_type\"],\n",
    "        \"retweet\": \"retweeted_status\" in tweet,\n",
    "        \"sentments\": sentments,\n",
    "        \"sent_score\": sum([sent_pesos[k] * v for k, v in sentments.items()])\n",
    "    }\n",
    "    \n",
    "    return structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### É criada uma função anônima para realizar o cálculo do índice para a predição do valor de cada criptomoeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lambda Nf, Nrt, S, Dtc : ((1+(Nf*0.01)+(Nrt*0.1))*(S*0.1))/(1+((Dtc-int(time()))*0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução do loop para captação dos dados no Twitter e cálculo do índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethereum 19.497089862862936 1661343959.3094568\n",
      "binance coin 3.815445145039569 1661344256.6665404\n",
      "bitcoin 7.831740516344648 1661344568.8751092\n",
      "ethereum 27.509773580163124 1661344816.1375194\n",
      "binance coin 3.1851311758291443 1661345099.894798\n",
      "bitcoin 3.726351158331289 1661345436.0237699\n",
      "ethereum 17.90791114165169 1661345733.3232286\n",
      "binance coin 50.99562707821537 1661345888.3315976\n",
      "bitcoin -4.017581663251486 1661346195.8877745\n",
      "ethereum 52.2195877089616 1661346499.0624008\n",
      "binance coin 2.372690922440257 1661346753.292207\n",
      "bitcoin 5.18693047709104 1661347008.5874763\n",
      "ethereum 24.119079212795558 1661347290.6838348\n",
      "binance coin 1.8361172912932742 1661347616.5214794\n",
      "bitcoin -12.9472165160452 1661347913.5348313\n",
      "ethereum 16.96517547968244 1661348218.299688\n",
      "binance coin 13.4630139403947 1661348440.6792126\n",
      "bitcoin -9.509223432897864 1661348702.804279\n",
      "ethereum 27.203689361832843 1661348975.4251952\n",
      "binance coin -1.0513971715365849 1661349179.167872\n",
      "bitcoin 5.006115177989847 1661349485.6976182\n",
      "ethereum 40.37169519277244 1661349814.027525\n",
      "binance coin -1.300348299341762 1661350020.7775073\n",
      "bitcoin 1.167522862026038 1661350321.7776594\n",
      "ethereum 21.499292916788125 1661350600.897062\n",
      "binance coin 0.23165778296358533 1661350834.098797\n",
      "bitcoin -0.04840423703798047 1661351143.0536869\n",
      "ethereum 33.7573940457522 1661351419.0731502\n",
      "binance coin 4.2939623258181925 1661351726.6981525\n",
      "bitcoin 8.141207935242463 1661352027.7274082\n",
      "ethereum 55.044550564181954 1661352328.9228284\n",
      "binance coin 6.532119691907684 1661352618.8118343\n",
      "bitcoin -2.2851729510239682 1661352895.4385917\n",
      "ethereum 12.548104138276317 1661353200.8140128\n",
      "binance coin 8.478423132966242 1661353477.4618871\n",
      "bitcoin 28.511741970164227 1661353792.5947416\n",
      "ethereum 18.074580643213807 1661354100.0516453\n",
      "binance coin 0.6955505454071074 1661354359.5205972\n",
      "bitcoin 16.26145273262877 1661354657.1510458\n",
      "ethereum 17.82374053527448 1661354953.9549952\n",
      "binance coin 17.5404766933013 1661355250.6417153\n",
      "bitcoin -0.008200494698660406 1661355564.9499247\n",
      "ethereum 33.37467693117324 1661355883.4906363\n",
      "binance coin 5.737593146953295 1661356166.0159507\n",
      "bitcoin -1.4152507743377958 1661356438.7770047\n",
      "ethereum 18.664929107321903 1661356718.4584675\n",
      "binance coin -6.856169260422997 1661356991.4250698\n",
      "bitcoin -3.93248422787536 1661357273.0038111\n",
      "ethereum 8.58940926949109 1661357590.0428836\n",
      "binance coin -0.5619180609181927 1661357690.1191418\n",
      "bitcoin 127.81844114828114 1661358001.3330061\n",
      "ethereum 15.421670497643554 1661358266.8074026\n",
      "binance coin 0.1155528364969074 1661358481.2825227\n",
      "bitcoin -18.26878918237323 1661358695.7890635\n",
      "ethereum 15.905627421556037 1661358967.6409502\n",
      "binance coin -3.9209204139878078 1661359201.3094163\n",
      "bitcoin 7.291483769916296 1661359432.9661717\n",
      "ethereum 30.580424864543243 1661359691.5756266\n",
      "binance coin -0.6067777295428243 1661359949.864863\n",
      "bitcoin -12.998610421051193 1661360218.812647\n",
      "ethereum 11.133928508576517 1661360516.3698716\n",
      "binance coin 3.816042242260963 1661360775.8019493\n",
      "bitcoin 9.68768228197298 1661361116.1134906\n",
      "ethereum 29.877960279543508 1661361371.6561823\n",
      "binance coin 7.44148319591549 1661361643.0922186\n",
      "bitcoin 19.630281951032757 1661361939.694803\n",
      "ethereum 2.792796235929819 1661362263.056285\n",
      "binance coin 4.2043826538713445 1661362584.7243907\n",
      "bitcoin -41.8968191650378 1661362938.902368\n",
      "ethereum 30.83550459540534 1661363275.713349\n",
      "binance coin 0.6052455170644985 1661363549.6949341\n",
      "bitcoin -35.13794081476999 1661363809.7256806\n",
      "ethereum 17.99355404894226 1661364101.2580445\n",
      "binance coin 0.11077811506435571 1661364396.828582\n",
      "bitcoin 4.184096857576172 1661364688.9628394\n",
      "ethereum 3.440762860482343 1661364957.4064667\n",
      "binance coin 3.6735609855769242 1661365238.3327494\n",
      "bitcoin 7.436912004378298 1661365528.654756\n",
      "ethereum 31.338241379700445 1661365801.0009484\n",
      "binance coin -3.1239387852111657 1661366047.1243236\n",
      "bitcoin 619.0009818492674 1661366370.0992403\n",
      "ethereum 14.319377373110552 1661366689.410533\n",
      "binance coin 0.1627762074031346 1661366773.3750472\n"
     ]
    }
   ],
   "source": [
    "step = 1\n",
    "while True:\n",
    "    crypto = [\"bitcoin\", \"ethereum\", \"binance coin\"][step % 3]\n",
    "    search = api.search_tweets(\n",
    "                                q = crypto, \n",
    "                                lang = \"en\", \n",
    "                                count = 200, \n",
    "                                result_type = \"recent\", \n",
    "                                tweet_mode = \"extended\"\n",
    "            )\n",
    "    tweets = [buildStructure(t) for t in search]\n",
    "    for t in tweets:\n",
    "        ans = cursor.execute(select_table_tweets.format(t[\"id\"]))\n",
    "        if not len(ans.fetchall()):\n",
    "            insert_tweets = insert_table_tweets.format(t[\"id\"], t[\"user_id\"], \" \".join(t[\"sentments\"].keys()), t[\"sent_score\"], int(t[\"favorited\"]), t[\"retweet_count\"], t[\"created_at\"], t[\"text\"], \", \".join(t[\"hashtags\"]), \", \".join(t[\"user_mentions\"]), \", \".join([u[\"url\"] for u in t[\"urls\"]]), t[\"type\"], int(t[\"retweet\"]), crypto)\n",
    "            cursor.execute(insert_table_tweets.format(t[\"id\"], t[\"user_id\"], \" \".join(t[\"sentments\"].keys()), t[\"sent_score\"], int(t[\"favorited\"]), t[\"retweet_count\"], t[\"created_at\"], t[\"text\"], \", \".join(t[\"hashtags\"]), \", \".join(t[\"user_mentions\"]), \", \".join([u[\"url\"] for u in t[\"urls\"]]), t[\"type\"], int(t[\"retweet\"]), crypto))\n",
    "        ans = cursor.execute(select_table_users.format(t[\"user_id\"]))\n",
    "        if len(ans.fetchall()):\n",
    "            cursor.execute(update_table_users.format(t[\"followers\"], t[\"user_id\"]))\n",
    "        else:\n",
    "            insert_user = insert_table_users.format(t[\"user_id\"], t[\"screen_name\"], t[\"followers\"])\n",
    "            cursor.execute(insert_table_users.format(t[\"user_id\"], t[\"screen_name\"], t[\"followers\"]))\n",
    "    index = sum([prediction(t[\"followers\"], t[\"retweet_count\"], t[\"sent_score\"], t[\"created_at\"]) for t in tweets])\n",
    "    cursor.execute(insert_table_indexes.format(step, index, crypto, time()))\n",
    "    conn.commit()\n",
    "    print(crypto, index, time())\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = cursor.execute(\"SELECT * FROM tweets\")\n",
    "ans.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
